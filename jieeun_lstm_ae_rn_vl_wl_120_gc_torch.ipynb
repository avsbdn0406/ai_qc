{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295b49ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ee2444d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# gpu 설정\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7e03da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Autoencoder 설계\n",
    "class LSTMAutoencoder(nn.Module):\n",
    "    def __init__(self, seq_len, n_features):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.n_features = n_features\n",
    "\n",
    "        self.encoder1 = nn.LSTM(input_size=n_features, hidden_size=16, batch_first=True)\n",
    "        self.encoder2 = nn.LSTM(input_size=16, hidden_size=8, batch_first=True)\n",
    "\n",
    "        self.decoder_input = nn.Linear(8, 8)\n",
    "        self.decoder1 = nn.LSTM(input_size=8, hidden_size=8, batch_first=True)\n",
    "        self.decoder2 = nn.LSTM(input_size=8, hidden_size=16, batch_first=True)\n",
    "        self.output_layer = nn.Linear(16, n_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.encoder1(x)\n",
    "        x, (h_n, _) = self.encoder2(x)\n",
    "        h_last = h_n[-1].unsqueeze(1).repeat(1, self.seq_len, 1)\n",
    "        x = self.decoder_input(h_last)\n",
    "        x, _ = self.decoder1(x)\n",
    "        x, _ = self.decoder2(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85cb360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data 셋 생성1\n",
    "# class SequenceDataset(Dataset):\n",
    "#     def __init__(self, data):\n",
    "#         self.data = data  # 이미 (n_seq, time_step, feature) 형태\n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "#     def __getitem__(self, idx):\n",
    "#         x = self.data[idx]\n",
    "#         return torch.from_numpy(x).float(), torch.from_numpy(x).float()\n",
    "\n",
    "\n",
    "# data 셋 생성2\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, data, seq_len):\n",
    "        self.data = data\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.seq_len + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx:idx + self.seq_len]\n",
    "        return torch.tensor(x, dtype=torch.float32), torch.tensor(x, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a204cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load & preprocess\n",
    "def data_load(path):\n",
    "    df = pd.read_csv(path)\n",
    "    df['dates'] = pd.to_datetime(df['dates'])\n",
    "    df.sort_values('dates', inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def data_sclaer(df,col):\n",
    "\n",
    "    df_scale = df.copy()\n",
    "\n",
    "    sclaer = MinMaxScaler()\n",
    "    \n",
    "    df_scale[col] = sclaer.fit_transform(df_scale[[col]])\n",
    "\n",
    "\n",
    "    return df_scale, sclaer\n",
    "\n",
    "# 학습용 데이터 shape 맞추기\n",
    "def data_shape(data,time_steps,col_list):\n",
    "    '''\n",
    "    data,time_steps,col_list\n",
    "    \n",
    "    return data(shape(row,time_steps,feature))\n",
    "    '''\n",
    "    data_list = []\n",
    "\n",
    "    for i in tqdm(range(len(data)-time_steps+1)):\n",
    "        data_list.append(data.loc[i:(i+time_steps-1),col_list].values)\n",
    "\n",
    "    data_list = np.array(data_list)\n",
    "\n",
    "    print(data_list.shape)\n",
    "\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da99b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터 정의\n",
    "time_step = 120\n",
    "batch = 32\n",
    "EPOCHS = 50\n",
    "feature = 3\n",
    "train_col = ['rn', 'vl', 'wl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e865f8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1223/394500 [00:11<55:57, 117.13it/s]  "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "gwangjoo_train_df = data_load('inter_data/2920010001045020.csv')\n",
    "changwon_train_df = data_load('inter_data/4812110001018020.csv')\n",
    "\n",
    "# 데이터 sclaer\n",
    "\n",
    "gwangjoo_train_data,g_rn_sclaer = data_sclaer(gwangjoo_train_df,'rn')\n",
    "gwangjoo_train_data,g_vl_sclaer = data_sclaer(gwangjoo_train_data,'vl')\n",
    "gwangjoo_train_data,g_wl_sclaer = data_sclaer(gwangjoo_train_data,'wl')\n",
    "changwon_train_data,c_rn_sclaer = data_sclaer(changwon_train_df,'rn')\n",
    "changwon_train_data,c_vl_sclaer = data_sclaer(changwon_train_data,'vl')\n",
    "changwon_train_data,c_wl_sclaer = data_sclaer(changwon_train_data,'wl')\n",
    "\n",
    "# # 데이터 shape\n",
    "gwangjoo_train_data = data_shape(gwangjoo_train_data,time_step,train_col)\n",
    "changwon_train_data = data_shape(changwon_train_data,time_step,train_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c27d050",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SequenceDataset(gwangjoo_train_data)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch, shuffle=True,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d5ec2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 정의\n",
    "model = LSTMAutoencoder(seq_len=time_step, n_features=feature).to(DEVICE)\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss = float('inf')  # 초기값 설정\n",
    "save_dir = \"torch_rv_60\"\n",
    "os.makedirs(save_dir, exist_ok=True)  # 저장 폴더 없으면 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd73979a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Loss: 0.007571\n",
      "Best model saved at epoch 1 with loss 0.007571\n",
      "Epoch 2/50 | Loss: 0.005274\n",
      "Best model saved at epoch 2 with loss 0.005274\n",
      "Epoch 3/50 | Loss: 0.002758\n",
      "Best model saved at epoch 3 with loss 0.002758\n",
      "Epoch 4/50 | Loss: 0.002519\n",
      "Best model saved at epoch 4 with loss 0.002519\n",
      "Epoch 5/50 | Loss: 0.002427\n",
      "Best model saved at epoch 5 with loss 0.002427\n",
      "Epoch 6/50 | Loss: 0.002352\n",
      "Best model saved at epoch 6 with loss 0.002352\n",
      "Epoch 7/50 | Loss: 0.002305\n",
      "Best model saved at epoch 7 with loss 0.002305\n",
      "Epoch 8/50 | Loss: 0.002257\n",
      "Best model saved at epoch 8 with loss 0.002257\n",
      "Epoch 9/50 | Loss: 0.002220\n",
      "Best model saved at epoch 9 with loss 0.002220\n",
      "Epoch 10/50 | Loss: 0.002179\n",
      "Best model saved at epoch 10 with loss 0.002179\n",
      "Epoch 11/50 | Loss: 0.002135\n",
      "Best model saved at epoch 11 with loss 0.002135\n",
      "Epoch 12/50 | Loss: 0.002111\n",
      "Best model saved at epoch 12 with loss 0.002111\n",
      "Epoch 13/50 | Loss: 0.002073\n",
      "Best model saved at epoch 13 with loss 0.002073\n",
      "Epoch 14/50 | Loss: 0.002049\n",
      "Best model saved at epoch 14 with loss 0.002049\n",
      "Epoch 15/50 | Loss: 0.002027\n",
      "Best model saved at epoch 15 with loss 0.002027\n",
      "Epoch 16/50 | Loss: 0.001992\n",
      "Best model saved at epoch 16 with loss 0.001992\n",
      "Epoch 17/50 | Loss: 0.001963\n",
      "Best model saved at epoch 17 with loss 0.001963\n",
      "Epoch 18/50 | Loss: 0.001939\n",
      "Best model saved at epoch 18 with loss 0.001939\n",
      "Epoch 19/50 | Loss: 0.001893\n",
      "Best model saved at epoch 19 with loss 0.001893\n",
      "Epoch 20/50 | Loss: 0.001733\n",
      "Best model saved at epoch 20 with loss 0.001733\n",
      "Epoch 21/50 | Loss: 0.001630\n",
      "Best model saved at epoch 21 with loss 0.001630\n",
      "Epoch 22/50 | Loss: 0.001599\n",
      "Best model saved at epoch 22 with loss 0.001599\n",
      "Epoch 23/50 | Loss: 0.001587\n",
      "Best model saved at epoch 23 with loss 0.001587\n",
      "Epoch 24/50 | Loss: 0.001569\n",
      "Best model saved at epoch 24 with loss 0.001569\n",
      "Epoch 25/50 | Loss: 0.001552\n",
      "Best model saved at epoch 25 with loss 0.001552\n",
      "Epoch 26/50 | Loss: 0.001539\n",
      "Best model saved at epoch 26 with loss 0.001539\n",
      "Epoch 27/50 | Loss: 0.001530\n",
      "Best model saved at epoch 27 with loss 0.001530\n",
      "Epoch 28/50 | Loss: 0.001526\n",
      "Best model saved at epoch 28 with loss 0.001526\n",
      "Epoch 29/50 | Loss: 0.001517\n",
      "Best model saved at epoch 29 with loss 0.001517\n",
      "Epoch 30/50 | Loss: 0.001508\n",
      "Best model saved at epoch 30 with loss 0.001508\n",
      "Epoch 31/50 | Loss: 0.001501\n",
      "Best model saved at epoch 31 with loss 0.001501\n",
      "Epoch 32/50 | Loss: 0.001495\n",
      "Best model saved at epoch 32 with loss 0.001495\n",
      "Epoch 33/50 | Loss: 0.001491\n",
      "Best model saved at epoch 33 with loss 0.001491\n",
      "Epoch 34/50 | Loss: 0.001479\n",
      "Best model saved at epoch 34 with loss 0.001479\n",
      "Epoch 35/50 | Loss: 0.001472\n",
      "Best model saved at epoch 35 with loss 0.001472\n",
      "Epoch 36/50 | Loss: 0.001464\n",
      "Best model saved at epoch 36 with loss 0.001464\n",
      "Epoch 37/50 | Loss: 0.001460\n",
      "Best model saved at epoch 37 with loss 0.001460\n",
      "Epoch 38/50 | Loss: 0.001453\n",
      "Best model saved at epoch 38 with loss 0.001453\n",
      "Epoch 39/50 | Loss: 0.001450\n",
      "Best model saved at epoch 39 with loss 0.001450\n",
      "Epoch 40/50 | Loss: 0.001442\n",
      "Best model saved at epoch 40 with loss 0.001442\n",
      "Epoch 41/50 | Loss: 0.001439\n",
      "Best model saved at epoch 41 with loss 0.001439\n",
      "Epoch 42/50 | Loss: 0.001430\n",
      "Best model saved at epoch 42 with loss 0.001430\n",
      "Epoch 43/50 | Loss: 0.001421\n",
      "Best model saved at epoch 43 with loss 0.001421\n",
      "Epoch 44/50 | Loss: 0.001407\n",
      "Best model saved at epoch 44 with loss 0.001407\n",
      "Epoch 45/50 | Loss: 0.001394\n",
      "Best model saved at epoch 45 with loss 0.001394\n",
      "Epoch 46/50 | Loss: 0.001381\n",
      "Best model saved at epoch 46 with loss 0.001381\n",
      "Epoch 47/50 | Loss: 0.001368\n",
      "Best model saved at epoch 47 with loss 0.001368\n",
      "Epoch 48/50 | Loss: 0.001354\n",
      "Best model saved at epoch 48 with loss 0.001354\n",
      "Epoch 49/50 | Loss: 0.001342\n",
      "Best model saved at epoch 49 with loss 0.001342\n",
      "Epoch 50/50 | Loss: 0.001333\n",
      "Best model saved at epoch 50 with loss 0.001333\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} | Loss: {avg_loss:.6f}\")\n",
    "\n",
    "    # ✅ Best loss 기준 저장\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        save_path = os.path.join(save_dir, f\"best_model_epoch{epoch+1}_loss{avg_loss:.6f}.pt\")\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        print(f\"Best model saved at epoch {epoch+1} with loss {avg_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3f518e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Dataset & DataLoader for changwon\n",
    "fine_dataset = SequenceDataset(changwon_train_data)\n",
    "fine_loader = DataLoader(fine_dataset, batch_size=batch, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dde27727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FineTune Epoch 1/50] Loss: 0.001653\n",
      "Fine-tuned model saved at epoch 1 with loss 0.001653\n",
      "[FineTune Epoch 2/50] Loss: 0.001577\n",
      "Fine-tuned model saved at epoch 2 with loss 0.001577\n",
      "[FineTune Epoch 3/50] Loss: 0.001555\n",
      "Fine-tuned model saved at epoch 3 with loss 0.001555\n",
      "[FineTune Epoch 4/50] Loss: 0.001546\n",
      "Fine-tuned model saved at epoch 4 with loss 0.001546\n",
      "[FineTune Epoch 5/50] Loss: 0.001534\n",
      "Fine-tuned model saved at epoch 5 with loss 0.001534\n",
      "[FineTune Epoch 6/50] Loss: 0.001526\n",
      "Fine-tuned model saved at epoch 6 with loss 0.001526\n",
      "[FineTune Epoch 7/50] Loss: 0.001518\n",
      "Fine-tuned model saved at epoch 7 with loss 0.001518\n",
      "[FineTune Epoch 8/50] Loss: 0.001512\n",
      "Fine-tuned model saved at epoch 8 with loss 0.001512\n",
      "[FineTune Epoch 9/50] Loss: 0.001508\n",
      "Fine-tuned model saved at epoch 9 with loss 0.001508\n",
      "[FineTune Epoch 10/50] Loss: 0.001504\n",
      "Fine-tuned model saved at epoch 10 with loss 0.001504\n",
      "[FineTune Epoch 11/50] Loss: 0.001500\n",
      "Fine-tuned model saved at epoch 11 with loss 0.001500\n",
      "[FineTune Epoch 12/50] Loss: 0.001496\n",
      "Fine-tuned model saved at epoch 12 with loss 0.001496\n",
      "[FineTune Epoch 13/50] Loss: 0.001492\n",
      "Fine-tuned model saved at epoch 13 with loss 0.001492\n",
      "[FineTune Epoch 14/50] Loss: 0.001493\n",
      "[FineTune Epoch 15/50] Loss: 0.001486\n",
      "Fine-tuned model saved at epoch 15 with loss 0.001486\n",
      "[FineTune Epoch 16/50] Loss: 0.001482\n",
      "Fine-tuned model saved at epoch 16 with loss 0.001482\n",
      "[FineTune Epoch 17/50] Loss: 0.001478\n",
      "Fine-tuned model saved at epoch 17 with loss 0.001478\n",
      "[FineTune Epoch 18/50] Loss: 0.001477\n",
      "Fine-tuned model saved at epoch 18 with loss 0.001477\n",
      "[FineTune Epoch 19/50] Loss: 0.001474\n",
      "Fine-tuned model saved at epoch 19 with loss 0.001474\n",
      "[FineTune Epoch 20/50] Loss: 0.001472\n",
      "Fine-tuned model saved at epoch 20 with loss 0.001472\n",
      "[FineTune Epoch 21/50] Loss: 0.001470\n",
      "Fine-tuned model saved at epoch 21 with loss 0.001470\n",
      "[FineTune Epoch 22/50] Loss: 0.001470\n",
      "Fine-tuned model saved at epoch 22 with loss 0.001470\n",
      "[FineTune Epoch 23/50] Loss: 0.001466\n",
      "Fine-tuned model saved at epoch 23 with loss 0.001466\n",
      "[FineTune Epoch 24/50] Loss: 0.001463\n",
      "Fine-tuned model saved at epoch 24 with loss 0.001463\n",
      "[FineTune Epoch 25/50] Loss: 0.001461\n",
      "Fine-tuned model saved at epoch 25 with loss 0.001461\n",
      "[FineTune Epoch 26/50] Loss: 0.001449\n",
      "Fine-tuned model saved at epoch 26 with loss 0.001449\n",
      "[FineTune Epoch 27/50] Loss: 0.001331\n",
      "Fine-tuned model saved at epoch 27 with loss 0.001331\n",
      "[FineTune Epoch 28/50] Loss: 0.001295\n",
      "Fine-tuned model saved at epoch 28 with loss 0.001295\n",
      "[FineTune Epoch 29/50] Loss: 0.001288\n",
      "Fine-tuned model saved at epoch 29 with loss 0.001288\n",
      "[FineTune Epoch 30/50] Loss: 0.001279\n",
      "Fine-tuned model saved at epoch 30 with loss 0.001279\n",
      "[FineTune Epoch 31/50] Loss: 0.001276\n",
      "Fine-tuned model saved at epoch 31 with loss 0.001276\n",
      "[FineTune Epoch 32/50] Loss: 0.001272\n",
      "Fine-tuned model saved at epoch 32 with loss 0.001272\n",
      "[FineTune Epoch 33/50] Loss: 0.001268\n",
      "Fine-tuned model saved at epoch 33 with loss 0.001268\n",
      "[FineTune Epoch 34/50] Loss: 0.001265\n",
      "Fine-tuned model saved at epoch 34 with loss 0.001265\n",
      "[FineTune Epoch 35/50] Loss: 0.001266\n",
      "[FineTune Epoch 36/50] Loss: 0.001260\n",
      "Fine-tuned model saved at epoch 36 with loss 0.001260\n",
      "[FineTune Epoch 37/50] Loss: 0.001257\n",
      "Fine-tuned model saved at epoch 37 with loss 0.001257\n",
      "[FineTune Epoch 38/50] Loss: 0.001254\n",
      "Fine-tuned model saved at epoch 38 with loss 0.001254\n",
      "[FineTune Epoch 39/50] Loss: 0.001254\n",
      "Fine-tuned model saved at epoch 39 with loss 0.001254\n",
      "[FineTune Epoch 40/50] Loss: 0.001252\n",
      "Fine-tuned model saved at epoch 40 with loss 0.001252\n",
      "[FineTune Epoch 41/50] Loss: 0.001260\n",
      "[FineTune Epoch 42/50] Loss: 0.001252\n",
      "[FineTune Epoch 43/50] Loss: 0.001246\n",
      "Fine-tuned model saved at epoch 43 with loss 0.001246\n",
      "[FineTune Epoch 44/50] Loss: 0.001248\n",
      "[FineTune Epoch 45/50] Loss: 0.001247\n",
      "[FineTune Epoch 46/50] Loss: 0.001242\n",
      "Fine-tuned model saved at epoch 46 with loss 0.001242\n",
      "[FineTune Epoch 47/50] Loss: 0.001243\n",
      "[FineTune Epoch 48/50] Loss: 0.001238\n",
      "Fine-tuned model saved at epoch 48 with loss 0.001238\n",
      "[FineTune Epoch 49/50] Loss: 0.001237\n",
      "Fine-tuned model saved at epoch 49 with loss 0.001237\n",
      "[FineTune Epoch 50/50] Loss: 0.001242\n"
     ]
    }
   ],
   "source": [
    "# 4. 추가 학습 파라미터\n",
    "EPOCHS_FINE = 50\n",
    "best_loss_fine = float('inf')\n",
    "fine_save_dir = \"torch_rvl_60\"\n",
    "os.makedirs(fine_save_dir, exist_ok=True)\n",
    "\n",
    "# 5. Fine-tuning loop\n",
    "for epoch in range(EPOCHS_FINE):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for x, y in fine_loader:\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    avg_loss = epoch_loss / len(fine_loader)\n",
    "    print(f\"[FineTune Epoch {epoch+1}/{EPOCHS_FINE}] Loss: {avg_loss:.6f}\")\n",
    "\n",
    "    # ✅ best weight 저장\n",
    "    if avg_loss < best_loss_fine:\n",
    "        best_loss_fine = avg_loss\n",
    "        save_path = os.path.join(fine_save_dir, f\"finetune_changwon_best_epoch{epoch+1}_loss{avg_loss:.6f}.pt\")\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        print(f\"Fine-tuned model saved at epoch {epoch+1} with loss {avg_loss:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c94b43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_qc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
